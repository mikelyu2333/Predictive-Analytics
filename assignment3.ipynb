{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assignment3.csv`  is the data for you to do analysis on.  It is the data to predict cars' prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The complete documentation on the dataset can be found here for your reference: https://archive.ics.uci.edu/ml/datasets/Automobile\n",
    "2. Delete rows with missing data points (denoted with \"?\")\n",
    "3. You should convert the data types of some features to the appropriate data types (i.e. float, integer, etc). Refer to the documentation\n",
    "4. You should be able to distinguish numerical from categorical features. Refer to documentation\n",
    "5. target = \\['price'\\]\n",
    "6. When doing \"train_test_split\", use random_state = 20190227\n",
    "7. You need to use Cross Validation and greedy algorithm method to find a best feature subset which gives us the smallest mean squared error corresponding validation set. Finally, compute the root mean squared error (RMSE) of test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the running time for this assignment could be long. Do not shut down the kernel when you run the codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we will not give you hints. You should use sklearn to do the analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('assignment3.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "data = data[~(data == '?').any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "symboling              int64\n",
       "normalized-losses     object\n",
       "make                  object\n",
       "fuel-type             object\n",
       "aspiration            object\n",
       "num-of-doors          object\n",
       "body-style            object\n",
       "drive-wheels          object\n",
       "engine-location       object\n",
       "wheel-base           float64\n",
       "length               float64\n",
       "width                float64\n",
       "height               float64\n",
       "curb-weight            int64\n",
       "engine-type           object\n",
       "num-of-cylinders      object\n",
       "engine-size            int64\n",
       "fuel-system           object\n",
       "bore                  object\n",
       "stroke                object\n",
       "compression-ratio    float64\n",
       "horsepower            object\n",
       "peak-rpm              object\n",
       "city-mpg               int64\n",
       "highway-mpg            int64\n",
       "price                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['normalized-losses','bore','stroke','horsepower','peak-rpm','price']].astype('float')\n",
    "features_numerical = ['normalized-losses','wheel-base','length','width','height','curb-weight','engine-size','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg']\n",
    "target = ['price']\n",
    "features_categorical = list(set(data.columns) - set(features_numerical) - set(target))\n",
    "features = features_categorical + features_numerical\n",
    "sales = data[features_numerical + features_categorical + target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoder(df, feature):\n",
    "    result = pd.DataFrame()\n",
    "    if feature in df.columns:\n",
    "        # The following line is important, refer to Assignment 2\n",
    "        result = pd.get_dummies(df, columns=[feature])\n",
    "        return result\n",
    "    else:\n",
    "        return print(\"Please select a feature in this df!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(data, target, proporiton):  \n",
    "    \n",
    "    # train valid split\n",
    "    train, valid = train_test_split(data, \n",
    "                                    test_size = proporiton, \n",
    "                                    random_state = 20190227) \n",
    "    \n",
    "    # extract X and Y to be fit in a model\n",
    "    X_train = train.drop(target, axis = 1)\n",
    "    Y_train = train[target]\n",
    "    X_valid = valid.drop(target, axis = 1)\n",
    "    Y_valid = valid[target]\n",
    "    \n",
    "    # build linear regression model\n",
    "    model = linear_model.LinearRegression()\n",
    "\n",
    "    # fit model using training data\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # predict using validation data\n",
    "    Y_valid_fit = model.predict(X_valid)\n",
    "    \n",
    "    return mean_squared_error(Y_valid_fit, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a list to save features\n",
    "greedy_select = []\n",
    "\n",
    "# and a numpy array to save their model MSE\n",
    "MSE_greedy_algo = np.array([])\n",
    "\n",
    "for i in range(len(features)):\n",
    "    MSE = np.array([])\n",
    "    features_left = list(set(features) - set(greedy_select))\n",
    "    \n",
    "    for new in features_left:\n",
    "        features_new = greedy_select + [new]\n",
    "        train_valid_sub = sales[features_new + target]\n",
    "        \n",
    "        # get all categorical features in sub\n",
    "        categorical_sub = list(set(features_new) & set(features_categorical))\n",
    "        \n",
    "         # if there really are categorical features, \n",
    "        # we need to do onthot encoding.\n",
    "        if len(categorical_sub) != 0:\n",
    "            for i in categorical_sub:\n",
    "                # Again, this line is important. Refer to Assignment 2\n",
    "                train_valid_sub = onehot_encoder(train_valid_sub, i)   \n",
    "            \n",
    "        # CrossValidation, compute the mse and save it into MSE_sub\n",
    "        MSE_sub = CrossValidation(train_valid_sub, 'price', 0.2)\n",
    "        MSE = np.append(MSE, MSE_sub)\n",
    "        \n",
    "    # pick the features that gives the smallest MSE\n",
    "    # and add it into our features list\n",
    "    # meanwhile, save the corresponding MSE\n",
    "    greedy_select += [features_left[MSE.argmin()]]\n",
    "    MSE_greedy_algo = np.append(MSE_greedy_algo, MSE.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['curb-weight',\n",
       " 'make',\n",
       " 'height',\n",
       " 'aspiration',\n",
       " 'body-style',\n",
       " 'stroke',\n",
       " 'symboling',\n",
       " 'width',\n",
       " 'engine-type',\n",
       " 'length',\n",
       " 'num-of-doors',\n",
       " 'engine-location']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_greedy = greedy_select[:(MSE_greedy_algo.argmin()+1)]\n",
    "sales_greedy = sales[features_greedy + target]\n",
    "features_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cv = list(set(features_greedy) & set(features_categorical))\n",
    "\n",
    "if len(categorical_cv) != 0:\n",
    "    for i in categorical_cv:\n",
    "        sales_greedy = onehot_encoder(sales_greedy, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_greedy, test_greedy = train_test_split(sales_greedy, test_size = 0.2, random_state = 20190227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1240.310026313878"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we build linear regression model\n",
    "model_greedy = linear_model.LinearRegression()\n",
    "\n",
    "# features traget split\n",
    "X_greedy = train_valid_greedy.drop(target, axis = 1)\n",
    "Y_greedy = train_valid_greedy[target]\n",
    "\n",
    "# fit model\n",
    "model_greedy.fit(X_greedy, Y_greedy)\n",
    "\n",
    "# Use model\n",
    "X_test_greedy = test_greedy.drop(target, axis = 1)\n",
    "Y_test_greedy = test_greedy[target]\n",
    "\n",
    "Y_test_greedy_fit = model_greedy.predict(X_test_greedy)\n",
    "np.sqrt(mean_squared_error(Y_test_greedy_fit, Y_test_greedy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
