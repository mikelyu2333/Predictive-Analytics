{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Survial Prediction by Logistic Regression\n",
    "\n",
    "We have some data about passengers on Titanic, refer to the file `titanic_data.csv`. The data contains 6 columns: \"Survived\", \"Sex\", \"Age\", \"SibSp\", \"Parch\" and \"Embarked\". Here are the variable descriptions:\n",
    "+ Survived - 1 means Yes and 0 menas No\n",
    "+ Sex - male and female, categorical data\n",
    "+ Age - numerical data\n",
    "+ SibSp - number of siblings/spouses aboard, numerical data\n",
    "+ Parch - number of parents/children aboard, numerical data\n",
    "+ Embarked - port of embarkation, C = Cherbourg; Q = Queenstown; S = Southampton, categorical data\n",
    "\n",
    "Our objective is to predict whether a passenger can survive or not. Set (\"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Embarked\") to be input variables and (\"Survived\") to be output variables. You need to finish the following things:\n",
    "1. Transform the categorical data \"Sex\" and \"Embarked\" to numerical data.\n",
    "2. Split the data set into training and testing parts with ratio 70:30.\n",
    "3. Setup a logistic regression model by `sklearn` and fit it using training data.\n",
    "4. Calculate the confusion matrix, precision and recall on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic_cross_validation.csv')\n",
    "titanic_data = pd.read_csv('titanic_data.csv')\n",
    "features_categorical = ['Sex','Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoder(df, feature):\n",
    "    result = pd.DataFrame()\n",
    "    if feature in df.columns:\n",
    "        # The following line is important, refer to Assignment 2\n",
    "        result = pd.get_dummies(df, columns=[feature])\n",
    "        return result\n",
    "    else:\n",
    "        return print(\"Please select a feature in this df!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in features_categorical:\n",
    "    titanic_data = onehot_encoder(titanic_data, i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(titanic_data, test_size = 0.3, random_state = 20190306)\n",
    "train = train.reset_index(drop = True)\n",
    "test = test.reset_index(drop = True)\n",
    "features = titanic_data.drop(['Survived'], axis = 1).columns\n",
    "target = ['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'SibSp', 'Parch', 'Sex_female', 'Sex_male', 'Embarked_C',\n",
       "       'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we build linear regression model\n",
    "model_selected = linear_model.LogisticRegression()\n",
    "\n",
    "# features traget split\n",
    "X = train.drop(target, axis = 1)\n",
    "Y = train[target]\n",
    "\n",
    "# fit model\n",
    "model_selected.fit(X, Y)\n",
    "\n",
    "# Use model\n",
    "X_test_model = test[features]\n",
    "Y_test_model = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,  29],\n",
       "       [ 36,  75]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test_model, model_selected.predict(X_test_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on this set is:  0.7565543071161048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80       156\n",
      "           1       0.72      0.68      0.70       111\n",
      "\n",
      "    accuracy                           0.76       267\n",
      "   macro avg       0.75      0.74      0.75       267\n",
      "weighted avg       0.76      0.76      0.76       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"The accuracy on this set is: \", model_selected.score(X_test_model, Y_test_model))\n",
    "print(classification_report(Y_test_model, model_selected.predict(X_test_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
